# ğŸ§  Project Assistant â€” RAG-basierter Code-Assistent

Ein intelligenter **LLM-gestÃ¼tzter Projektassistent** fÃ¼r Python-Projekte.
Der Assistent durchsucht automatisch dein Repository, erzeugt Embeddings, fasst Dateien zusammen, und beantwortet Fragen zu deinem Code bzw. ergÃ¤nzt neuen Code mit **RAG (Retrieval-Augmented Generation)**.
Zudem zeigt er Ã¼ber eine **Gradio-GUI** vorgeschlagene DateiÃ¤nderungen samt Diffs an.

---

## ğŸš€ Features

* ğŸ” **Automatischer Projekt-Scan**

  * Erkennt Python-Dateien, ignoriert `.gitignore`-EintrÃ¤ge.
  * Erstellt eine visuelle **Projektstruktur** in `data/structure.md`.

* ğŸ’¬ **LLM-Integration**

  * Erzeugt intelligente Kurzbeschreibungen jeder Datei.
  * Nutzt ein konfigurierbares Sprachmodell (z. B. `ollama`, `gpt-4`, `mistral`, â€¦).
  * Speichert alle Prompts unter `logs/prompts/`.

* ğŸ¤© **Vektorsuche mit FAISS**

  * Erzeugt Embeddings fÃ¼r jede Datei.
  * Kombination aus Keyword- und Vektorsuche zur Relevanzbewertung.

* ğŸ§¶ **GUI (Gradio)**

  * Einfacher Chat-Workflow: Eingabe deiner Frage â†’ Anzeige der betroffenen Dateien â†’ Vorschau & Anwendung der Ã„nderungen.
  * Diff-Ansicht fÃ¼r jede vom LLM vorgeschlagene Ã„nderung.
  * Automatische Backups bei DateischreibvorgÃ¤ngen (`.bak`).

---

## ğŸ§ª Projektstruktur

```plaintext
project-assistant/
â”œâ”€â”€ assistant/           
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ structure.md           # Projektstruktur in Markdown
â”‚   â”œâ”€â”€ descriptions.json      # Cache der Kurzbeschreibungen
â”‚   â”œâ”€â”€ vector.index           # FAISS-Vektorindex
â”‚   â””â”€â”€ embeddings_map.json    # Mapping ID â†’ Datei
â”œâ”€â”€ gui/
â”‚   â”œâ”€â”€ __init__.py           
â”‚   â””â”€â”€ chatbot.py             
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ prompts/               # Gespeicherte LLM-Prompts
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py           
â”‚   â””â”€â”€ file_ops.py      
â”œâ”€â”€ .gitignore
â”œâ”€â”€ environment.yml
â”œâ”€â”€ LICENSE
â”œâ”€â”€ main.py                    # CLI-Startpunkt / Scanner / App launcher
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Voraussetzungen

* **Python 3.10+**
* **FAISS**, **Ollama** (lokales LLM) oder eine OpenAI-kompatible API
* **Gradio** fÃ¼r die BenutzeroberflÃ¤che

### 2ï¸âƒ£ AbhÃ¤ngigkeiten installieren

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Optional: Ollama installieren (fÃ¼r lokale LLMs)

[https://ollama.com/download](https://ollama.com/download)

Beispielmodell laden:

```bash
ollama pull llama3
```

---

## ğŸ§  Verwendung

### ğŸ”¹ Projekt scannen und GUI starten

Erzeugt Struktur, Metadaten, Embeddings und startet GUI:

```bash
python main.py
```

Die GUI Ã¶ffnet sich im Browser unter:
ğŸ”— [http://127.0.0.1:7860](http://127.0.0.1:7860)

---

## ğŸ¥‰ Arbeitsweise (KurzÃ¼berblick)

1. **ProjectScanner**

   * LÃ¤dt `.gitignore`-Regeln.
   * Liest und beschreibt alle `.py`-Dateien.
   * Speichert Kurzbeschreibungen im Cache.
   * Erstellt VektorreprÃ¤sentationen (Embeddings) der Dateibeschreibungen.

2. **FAISSStore**

   * Speichert Embeddings und Datei-Mapping.
   * ErmÃ¶glicht schnelle semantische Suche nach relevanten Dateien.

3. **RAGSearcher**

   * Kombiniert Keyword-Suche und Embedding-Suche.
   * Ermittelt relevante Dateien fÃ¼r eine Nutzeranfrage.

4. **Gradio-GUI**

   * Interaktive ChatoberflÃ¤che fÃ¼r Nutzeranfragen.
   * Zeigt LLM-Antworten und vorgeschlagene DateiÃ¤nderungen.

---

## ğŸ”’ Datenschutz & Sicherheit

* Lokale Speicherung aller Embeddings und Prompts.
* Keine DatenÃ¼bertragung an Dritte ohne explizite API-Konfiguration.

---

## ğŸ’¡ Tipps

* Scanne dein Projekt regelmÃ¤ÃŸig, um neue Dateien zu erfassen.
* Cache-Datei `data/descriptions.json` kann gefahrlos gelÃ¶scht werden, um neue Beschreibungen zu erzwingen.
* Bei LLM-Fehlern prÃ¼fe deine Umgebungsvariable (`OLLAMA_API_BASE` oder `OPENAI_API_KEY`).

---

## ğŸ‘¨â€ğŸ’» Autor

**Daniel Gaida**
Technische Hochschule KÃ¶ln
âœ¨ Open Source unter MIT-Lizenz
